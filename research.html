<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/2f71e0d51b6954c9.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1a63c02c6252f740.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/f1b13c82e5571f85.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-e2e0a1c46b58ac5a.js"/><script src="/_next/static/chunks/fd9d1056-6184565b3c21c232.js" async=""></script><script src="/_next/static/chunks/23-a6fd6170b6cfa730.js" async=""></script><script src="/_next/static/chunks/main-app-1b00a96d9acce1b3.js" async=""></script><script src="/_next/static/chunks/215-ce12f954edb9789c.js" async=""></script><script src="/_next/static/chunks/app/layout-349bc3fb2144d191.js" async=""></script><title>Davide Morelli</title><meta name="description" content="My portfolio website"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_aaf875"><nav class="navbar navbar-expand-lg bg-body-tertiary"><div class="container-fluid"><a class="nav-link active" aria-current="page" href="/">Home</a><a class="ms-auto" href="/research">Research</a></div></nav><main><div class="container text-center"><div class="row p-4"><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2022</div><a href="Dress Code: High-Resolution Multi-Category Virtual Try-On" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Dress Code: High-Resolution Multi-Category Virtual Try-On</a><p class="mt-2 text-slate-500 pub-authors">D Morelli, M Fincato, M Cornia, F Landi, F Cesari, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern�…, 2022</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2020</div><a href="Design of modern supply chain networks using fuzzy bargaining game and data envelopment analysis" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Design of modern supply chain networks using fuzzy bargaining game and data envelopment analysis</a><p class="mt-2 text-slate-500 pub-authors">G Cavone, M Dotoli, N Epicoco, D Morelli, C Seatzu</p><p class="mt-2 text-slate-500 pub-journal">IEEE Transactions on Automation Science and Engineering 17 (3), 1221-1236, 2020</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2023</div><a href="LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On</a><p class="mt-2 text-slate-500 pub-authors">D Morelli, A Baldrati, G Cartella, M Cornia, M Bertini, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">Proceedings of the 31th ACM International Conference on Multimedia, 2023</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2023</div><a href="Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing</a><p class="mt-2 text-slate-500 pub-authors">A Baldrati, D Morelli, G Cartella, M Cornia, M Bertini, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">Proceedings of the IEEE/CVF International Conference on Computer Vision�…, 2023</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2023</div><a href="Parents and children: Distinguishing multimodal deepfakes from natural images" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Parents and children: Distinguishing multimodal deepfakes from natural images</a><p class="mt-2 text-slate-500 pub-authors">R Amoroso, D Morelli, M Cornia, L Baraldi, A Del Bimbo, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">arXiv preprint arXiv:2304.00500, 2023</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2023</div><a href="Fashion-oriented image captioning with external knowledge retrieval and fully attentive gates" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Fashion-oriented image captioning with external knowledge retrieval and fully attentive gates</a><p class="mt-2 text-slate-500 pub-authors">N Moratelli, M Barraco, D Morelli, M Cornia, L Baraldi, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">Sensors 23 (3), 1286, 2023</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2018</div><a href="A game-theoretical design technique for multi-stage supply chains under uncertainty" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">A game-theoretical design technique for multi-stage supply chains under uncertainty</a><p class="mt-2 text-slate-500 pub-authors">G Cavone, M Dotoli, N Epicoco, D Morelli, C Seatzu</p><p class="mt-2 text-slate-500 pub-journal">2018 IEEE 14th International Conference on Automation Science and�…, 2018</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2021</div><a href="A convolution residual network for heating-invariant defect segmentation in composite materials inspected by lock-in thermography" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">A convolution residual network for heating-invariant defect segmentation in composite materials inspected by lock-in thermography</a><p class="mt-2 text-slate-500 pub-authors">D Morelli, R Marani, E D’Accardi, D Palumbo, U Galietti, T D’Orazio</p><p class="mt-2 text-slate-500 pub-journal">IEEE Transactions on Instrumentation and Measurement 70, 1-14, 2021</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2022</div><a href="Dual-Branch Collaborative Transformer for Virtual Try-On" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Dual-Branch Collaborative Transformer for Virtual Try-On</a><p class="mt-2 text-slate-500 pub-authors">F Emanuele, D Morelli, M Cornia, L Baraldi, C Fabio, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern�…, 2022</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2021</div><a href="FashionSearch++: Improving consumer-to-shop clothes retrieval with hard negatives" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">FashionSearch++: Improving consumer-to-shop clothes retrieval with hard negatives</a><p class="mt-2 text-slate-500 pub-authors">D Morelli, M Cornia, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">CEUR Workshop Proceedings 2947, 2021</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2022</div><a href="Defect detection by a deep learning approach with active IR thermography" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Defect detection by a deep learning approach with active IR thermography</a><p class="mt-2 text-slate-500 pub-authors">G Guaragnella, D Morelli, T D&#x27;Orazio, U Galietti, B Trentadue, R Marani</p><p class="mt-2 text-slate-500 pub-journal">2022 8th International Conference on Control, Decision and Information�…, 2022</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2023</div><a href="OpenFashionCLIP: Vision-and-language contrastive learning with open-source fashion data" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">OpenFashionCLIP: Vision-and-language contrastive learning with open-source fashion data</a><p class="mt-2 text-slate-500 pub-authors">G Cartella, A Baldrati, D Morelli, M Cornia, M Bertini, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">International Conference on Image Analysis and Processing, 245-256, 2023</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2024</div><a href="Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing</a><p class="mt-2 text-slate-500 pub-authors">A Baldrati, D Morelli, M Cornia, M Bertini, R Cucchiara</p><p class="mt-2 text-slate-500 pub-journal">arXiv preprint arXiv:2403.14828, 2024</p></div></div></div><div class="max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl"><div class="md:flex"><div class="p-8"><div class="uppercase tracking-wide text-sm text-indigo-500 font-semibold">2020</div><a href="Reti attentive per estrazione di feature a livello video e action recognition" class="block mt-1 text-lg leading-tight font-medium text-black hover:underline">Reti attentive per estrazione di feature a livello video e action recognition</a><p class="mt-2 text-slate-500 pub-authors">D MORELLI</p><p class="mt-2 text-slate-500 pub-journal"></p></div></div></div></div></div></main><script src="/_next/static/chunks/webpack-e2e0a1c46b58ac5a.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/2f71e0d51b6954c9.css\",\"style\"]\n2:HL[\"/_next/static/css/1a63c02c6252f740.css\",\"style\"]\n3:HL[\"/_next/static/css/f1b13c82e5571f85.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n7:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[231,[\"215\",\"static/chunks/215-ce12f954edb9789c.js\",\"185\",\"static/chunks/app/layout-349bc3fb2144d191.js\"],\"\"]\na:I[8621,[\"215\",\"static/chunks/215-ce12f954edb9789c.js\",\"185\",\"static/chunks/app/layout-349bc3fb2144d191.js\"],\"default\"]\nc:I[6130,[],\"\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2f71e0d51b6954c9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1a63c02c6252f740.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f1b13c82e5571f85.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"WNPrwAEfz4E_09lZSb5QQ\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/research\",\"initialTree\":[\"\",{\"children\":[\"research\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"research\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",\"$L6\"],null],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"research\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"body\",null,{\"className\":\"__className_aaf875\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"navbar navbar-expand-lg bg-body-tertiary\",\"children\":[\"$\",\"div\",null,{\"className\":\"container-fluid\",\"children\":[[\"$\",\"$L9\",null,{\"className\":\"nav-link active\",\"aria-current\":\"page\",\"href\":\"/\",\"children\":\"Home\"}],[\"$\",\"$L9\",null,{\"className\":\"ms-auto\",\"href\":\"/research\",\"children\":\"Research\"}]]}]}],[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]]}],[\"$\",\"$La\",null,{}]]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Davide Morelli\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"My portfolio website\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n5:null\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"main\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"container text-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"row p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2022\"}],[\"$\",\"a\",null,{\"href\":\"Dress Code: High-Resolution Multi-Category Virtual Try-On\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Dress Code: High-Resolution Multi-Category Virtual Try-On\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"D Morelli, M Fincato, M Cornia, F Landi, F Cesari, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern�…, 2022\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2020\"}],[\"$\",\"a\",null,{\"href\":\"Design of modern supply chain networks using fuzzy bargaining game and data envelopment analysis\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Design of modern supply chain networks using fuzzy bargaining game and data envelopment analysis\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"G Cavone, M Dotoli, N Epicoco, D Morelli, C Seatzu\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"IEEE Transactions on Automation Science and Engineering 17 (3), 1221-1236, 2020\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2023\"}],[\"$\",\"a\",null,{\"href\":\"LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"D Morelli, A Baldrati, G Cartella, M Cornia, M Bertini, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"Proceedings of the 31th ACM International Conference on Multimedia, 2023\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2023\"}],[\"$\",\"a\",null,{\"href\":\"Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"A Baldrati, D Morelli, G Cartella, M Cornia, M Bertini, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"Proceedings of the IEEE/CVF International Conference on Computer Vision�…, 2023\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2023\"}],[\"$\",\"a\",null,{\"href\":\"Parents and children: Distinguishing multimodal deepfakes from natural images\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Parents and children: Distinguishing multimodal deepfakes from natural images\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"R Amoroso, D Morelli, M Cornia, L Baraldi, A Del Bimbo, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"arXiv preprint arXiv:2304.00500, 2023\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2023\"}],[\"$\",\"a\",null,{\"href\":\"Fashion-oriented image captioning with external knowledge retrieval and fully attentive gates\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Fashion-oriented image captioning with external knowledge retrieval and fully attentive gates\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"N Moratelli, M Barraco, D Morelli, M Cornia, L Baraldi, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"Sensors 23 (3), 1286, 2023\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2018\"}],[\"$\",\"a\",null,{\"href\":\"A game-theoretical design technique for multi-stage supply chains under uncertainty\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"A game-theoretical design technique for multi-stage supply chains under uncertainty\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"G Cavone, M Dotoli, N Epicoco, D Morelli, C Seatzu\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"2018 IEEE 14th International Conference on Automation Science and�…, 2018\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2021\"}],[\"$\",\"a\",null,{\"href\":\"A convolution residual network for heating-invariant defect segmentation in composite materials inspected by lock-in thermography\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"A convolution residual network for heating-invariant defect segmentation in composite materials inspected by lock-in thermography\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"D Morelli, R Marani, E D’Accardi, D Palumbo, U Galietti, T D’Orazio\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"IEEE Transactions on Instrumentation and Measurement 70, 1-14, 2021\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2022\"}],[\"$\",\"a\",null,{\"href\":\"Dual-Branch Collaborative Transformer for Virtual Try-On\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Dual-Branch Collaborative Transformer for Virtual Try-On\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"F Emanuele, D Morelli, M Cornia, L Baraldi, C Fabio, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern�…, 2022\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2021\"}],[\"$\",\"a\",null,{\"href\":\"FashionSearch++: Improving consumer-to-shop clothes retrieval with hard negatives\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"FashionSearch++: Improving consumer-to-shop clothes retrieval with hard negatives\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"D Morelli, M Cornia, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"CEUR Workshop Proceedings 2947, 2021\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2022\"}],[\"$\",\"a\",null,{\"href\":\"Defect detection by a deep learning approach with active IR thermography\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Defect detection by a deep learning approach with active IR thermography\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"G Guaragnella, D Morelli, T D'Orazio, U Galietti, B Trentadue, R Marani\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"2022 8th International Conference on Control, Decision and Information�…, 2022\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2023\"}],[\"$\",\"a\",null,{\"href\":\"OpenFashionCLIP: Vision-and-language contrastive learning with open-source fashion data\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"OpenFashionCLIP: Vision-and-language contrastive learning with open-source fashion data\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"G Cartella, A Baldrati, D Morelli, M Cornia, M Bertini, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"International Conference on Image Analysis and Processing, 245-256, 2023\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2024\"}],[\"$\",\"a\",null,{\"href\":\"Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Multimodal-Conditioned Latent Diffusion Models for Fashion Image Editing\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"A Baldrati, D Morelli, M Cornia, M Bertini, R Cucchiara\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"arXiv preprint arXiv:2403.14828, 2024\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md my-10 mx-auto bg-white rounded-xl shadow-md overflow-hidden md:max-w-2xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"md:flex\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"uppercase tracking-wide text-sm text-indigo-500 font-semibold\",\"children\":\"2020\"}],[\"$\",\"a\",null,{\"href\":\"Reti attentive per estrazione di feature a livello video e action recognition\",\"className\":\"block mt-1 text-lg leading-tight font-medium text-black hover:underline\",\"children\":\"Reti attentive per estrazione di feature a livello video e action recognition\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-authors\",\"children\":\"D MORELLI\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-slate-500 pub-journal\",\"children\":\"\"}]]}]}]}]]}]}]}]\n"])</script></body></html>